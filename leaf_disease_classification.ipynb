{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://kds-e118bcdb309cf88b7f9e4a96ee84997123a5781b886180ffc13d3fc9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [512, 512], #length and width will be equal\n",
    "    'epochs': 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('label').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_train(tfrec):\n",
    "    '''\n",
    "    ***update documentation \n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "#     decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "#     img_name = features['image_name'] #I dont think I will need this\n",
    "    target = features['target']\n",
    "    \n",
    "    return decoded_image, target #,img_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(image, label):\n",
    "    '''\n",
    "    function to one hot encode label\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "        \n",
    "    returns:\n",
    "        image: tensor, same as input\n",
    "        label: tensor, one hot encoded with a depth of 5\n",
    "    '''\n",
    "    label = tf.one_hot(label, 5)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "          cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(one_hot, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/train_tfrecords/*.tfrec'),\n",
    "                                            test_size=.1, random_state=1)\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "print('the dataset consists of: {} training images, and {} validation images'.\n",
    "     format(train_size, valid_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps = train_size // params['batch_size'] \n",
    "valid_steps = valid_size // params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train_df.groupby('label').count()['image_id'].to_list()\n",
    "#todo - consider using class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3]):\n",
    "    '''\n",
    "    function to create model\n",
    "    '''\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    \n",
    "    resized = layers.experimental.preprocessing.Resizing(299, 299)(input_tensor)\n",
    "    xception = tf.keras.applications.Xception(include_top=False, classes=5, input_shape=[299, 299,3])(resized)\n",
    "    end_of_xception = layers.GlobalAveragePooling2D()(xception)\n",
    "    dense_layers = layers.Dense(8)(end_of_xception)\n",
    "    output = layers.Dense(5, activation='softmax')(dense_layers)\n",
    "    model = keras.Model(inputs=input_tensor, outputs=output) \n",
    "    \n",
    "    metrics = [\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#         keras.metrics.SparseTopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.01),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                patience=25,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "def lr_schedule_fn(epoch, lr):\n",
    "    if epoch < 8:\n",
    "        return 0.000001\n",
    "    elif epoch == 8:\n",
    "        return 0.001\n",
    "    elif epoch %2 ==0 and epoch < 49:\n",
    "        return lr * 0.75\n",
    "    else:\n",
    "        return lr\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_schedule_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "#     class_weight=class_weights,\n",
    "    callbacks=[early_stopping, lr_schedule],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-addiction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
